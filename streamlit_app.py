# -*- coding: utf-8 -*-
"""streamlit_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16vXUvQoNciyGVmhQOIy5Toq8YRxtTKev

#This Streamlit app builds a simple chatbot using a Hugging Face-based LLM via transformers.
"""

import streamlit as st
from transformers import pipeline, AutoTokenizer, TFGPT2LMHeadModel

# Set Streamlit page title
st.set_page_config(page_title="ðŸ¤– Hugging Face LLM Chatbot")

# Title of the app
st.title("ðŸ¤— Hugging Face Chatbot using GPT-2")

# Load tokenizer and model from Hugging Face Hub
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("gpt2")
    model = TFGPT2LMHeadModel.from_pretrained("gpt2", from_pt=True)
    generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
    return generator

generator = load_model()

# Text input from the user
with st.form("chat_form"):
    user_input = st.text_area("Enter your question:")
    submitted = st.form_submit_button("Ask")

    if submitted and user_input:
        with st.spinner("Generating response..."):
            response = generator(user_input, max_length=100, do_sample=True, top_k=50, top_p=0.95)[0]['generated_text']
            st.markdown("### ðŸ’¬ Chatbot Response:")
            st.success(response)

